###

# 1. 通用爬虫思路
- 1. 准备URL
    - 准备start_url
        - url地址规律不明显，总数不确定
        - 通过代码查找下一页url
            - xpath定位
            - 不明显，寻找url地址，部分参数可能放在当前的响应中（比如当前页码数和总页码数会在当前响应中）
    - 准备url_list
        - 页码总数明确
        - url地址规律明显  
        
- 2. 发送请求，获取响应   
    - 添加随机的User-Agent，反反爬虫
    - 添加随机代理的IP，建立ip代理池，反反爬虫
    - 在对方判断我们是爬虫后，应该添加更多的headers字段，包括cookie
        - cookie的处理可以使用session模块解决
        - 准备一堆可以使用的cookie，组成cookie池
            - 如果不登录
                - 准备刚开始可以成功请求网址的cookie，即接收对方网址设置在response中的cookie
                - 下一次请求的时候，使用之前的cookie来请求
            - 如果要登录
                - 准备多个账号
                - 使用程序获取每个账号的cookie
                - 之后请求登录之后才能访问的网址随机使用已有的cookie
            
- 3. 提取数据
    - 确定数据的位置
        - 如果数据在当前的url地址响应中
            - 提取的是列表页的数据(第一层)
            - 提取详情页的数据(第二层)
                - 寻找详情页的url，发送请求，提取数据，返回数据存储
        - 如果数据不在当前的url地址相应中
            - 在其他的响应中，寻找数据的位置
                - 1. 从network结果中从上往下找
                - 2. 使用Chrome中的过滤条件，选择出js.css.img之外的按钮选项
                - 3. 使用Chrome中的search all file，搜索关键数字和英文
    - 数据提取 
        - xpath,从html提取数据，进行分组，之后每一组再进行提取
        - re,提取特定的字符串
        - json数据，转换为python字典，然后re查找提取         
    
- 4. 保存
    - 保存在本地，txt,json,csv
    - 保存到数据库    