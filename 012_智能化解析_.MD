# 1 智能化解析介绍
- 什么是智能化解析？
    - 所谓爬虫的智能化解析，顾名思义就是不再需要我们针对某一些页面来专门写提取规则了，
    - 我们可以利用一些算法来计算出页面特定元素的位置和提取路径。
    - 比如一个页面中的一篇文章，我们可以通过算法计算出来，它的标题应该是什么，正文应该是哪部分区域，发布时间等等。

- 智能化解析任务
    - 其实智能化解析是非常难的一项任务，比如说你给人看一个网页的一篇文章，
    - 人可以迅速找到这篇文章的标题是什么，发布时间是什么，正文是哪一块，或者哪一块是广告位，
    - 哪一块是导航栏。但给机器来识别的话，它面临的是什么？仅仅是一系列的 HTML 代码而已。
    - 那究竟机器是怎么做到智能化提取的呢？其实这里面融合了多方面的信息。

- 智能化解析举例
    - 比如标题。一般它的字号是比较大的，而且长度不长，位置一般都在页面上方，而且大部分情况下它应该和 title 标签里的内容是一致的。
    - 比如正文。它的内容一般是最多的，而且会包含多个段落 p 或者图片 img 标签，另外它的宽度一般可能会占用到页面的三分之二区域，并且密度（字数除以标签数量）会比较大。
    - 比如时间。不同语言的页面可能不同，但时间的格式是有限的，如 2019-02-20 或者 2019/02/20 等等，也有可能是美式的记法，顺序不同，这些也有特定的模式可以识别。
    - 比如广告。它的标签一般可能会带有 ads 这样的字样，另外大多数可能会处于文章底部、页面侧栏，并可能包含一些特定的外链内容。
    - 另外还有一些特点就不再一一赘述了，这其中包含了区块位置、区块大小、区块标签、区块内容、区块疏密度等等多种特征，
    - 另外很多情况下还需要借助于视觉的特征，所以说这里面其实结合了算法计算、视觉处理、自然语言处理等各个方面的内容。
    - 如果能把这些特征综合运用起来，再经过大量的数据训练，是可以得到一个非常不错的效果的。
    
# 2 智能化解析业界进展
- 未来的话，页面也会越来越多，页面的渲染方式也会发生很大的变化，爬虫也会越来越难做，智能化爬虫也将会变得越来越重要。
- 目前工业界，其实已经有落地的算法应用了。经过我的一番调研，发现目前有这么几种算法或者服务对页面的智能化解析做得比较好：
    - Diffbot，国外的一家专门做智能化解析服务的公司，https://www.diffbot.com。
    - Boilerpipe，Java 语言编写的一个页面解析算法，https://github.com/kohlschutter/boilerpipe。
    - Embedly，提供页面解析服务的公司，https://embed.ly/extract。
    - Readability，是一个页面解析算法，但现在官方的服务已经关闭了，https://www.readability.com/。
    - Mercury，Readability 的替代品，https://mercury.postlight.com/。
    - Goose，Java 语音编写的页面解析算法，https://github.com/GravityLabs/goose。
    - 其中，Diffbot 的准确率和召回率都还比较高，Diffbot 也一直致力于这一方面的服务，整个 Diffbot 就是页面解析起家的，现在也一直专注于页面解析服务
    
# 3 Diffbot 简单使用
- Diffbot 页面解析
    - 首先我们需要注册一个账号，它有 15 天的免费试用，注册之后会获得一个 Developer Token，这就是使用 Diffbot 接口服务的凭证。
    - 接下来切换到它的测试页面中，链接为：https://www.diffbot.com/dev/home/，我们来测试一下它的解析效果到底是怎样的。
    - 这里我们选择的测试页面就是上文所述的页面，链接为：https://news.ifeng.com/c/7kQcQG2peWU，API 类型选择 Article API，然后点击 Test Drive 按钮，接下来它就会出现当前页面的解析结果

- Diffbot API
    - Driffbot 提供了多种 API，如 Analyze API、Article API、Disscussion API 等。
    - 下面我们以 Article API 为例来说明一下它的用法，
    - 其官方文档地址为：https://www.diffbot.com/dev/docs/article/，
    - API 调用地址为：https://api.diffbot.com/v3/article
    - 我们可以用 GET 方式来进行请求，其中的 Token 和 URL 都可以以参数形式传递给这个 API，其必备的参数有：
        - token：即 Developer Token；
        - url：即要解析的 URL 链接。
        
    - 另外它还有几个可选参数。
        - fields：用来指定返回哪些字段，默认已经有了一些固定字段，这个参数可以指定还可以额外返回可选字段。
        - paging：针对多页文章，如果将这个参数设置为 false 则可以禁止多页内容拼接。
        - maxTags：可以设置返回的 Tag 最大数量，默认是 10 个。
        - tagConfidence：设置置信度的阈值，超过这个值的 Tag 才会被返回，默认是 0.5。
        - discussion：如果将这个参数设置为 false，那么就不会解析评论内容。
        - timeout：在解析的时候等待的最长时间，默认是 30 秒。
        - callback：为 JSONP 类型的请求而设计的回调。
    - 更多参数查看：https://kaiwu.lagou.com/course/courseInfo.htm?courseId=46#/detail/pc?id=1697

- Diffbot 使用实例，返回 json 格式数据
```python
import requests, json

url = 'https://api.diffbot.com/v3/article'
params = {
    'token': '77b41f6fbb24496d5113d528306528fa',
    'url': 'https://news.ifeng.com/c/7kQcQG2peWU',
    'fields': 'meta' 
}
response = requests.get(url, params=params)
print(json.dumps(response.json(), indent=2, ensure_ascii=False))

```
- 首先定义了 API 的链接，然后指定了 params 参数，即 GET 请求参数。
- 参数中包含了必选的 token、url 字段，也设置了可选的 fields 字段，
- 其中 fields 为可选的扩展字段 meta 标签，返回 meta 标签里面的内容。


# 4 Diffbot SDK
- Diffbot 还提供了几乎所有语言的 SDK 支持，我们也可以使用 SDK 来实现如上功能，
- 链接为：https://www.diffbot.com/dev/docs/libraries/，
- 如果你使用 Python 的话，可以直接使用 Python 的 SDK 即可，
- Python 的 SDK 链接为：https://github.com/diffbot/diffbot-python-client。
- 这个库并没有发布到 PyPi，需要自己下载并导入使用，另外这个库是使用 Python 2 写的，
- 其实本质上就是调用了 requests 库，如果你感兴趣的话可以看一下。

- 调用示例：
```python
from client import DiffbotClient,DiffbotCrawl

diffbot = DiffbotClient()
token = 'your_token'
url = 'http://shichuan.github.io/javascript-patterns/'
api = 'article'
response = diffbot.request(url, token, api)
```
- 通过这行代码我们就可以通过调用 Article API 来分析我们想要的 URL 链接了，返回结果是类似的。
- 具体的用法你直接看下它的源码注释就一目了然了，还是很清楚的。


# 5 智能化解析实现原理
- 新闻类网站最核心的几个字段的智能解析方法：
    - 标题
    - 正文
    - 发布时间
    - 作者

- 标题
    - 两个提取思路：
    - 提取页面的 h 节点，如 h1、h2 等节点内容，然后将内容和 title 的文本进行比对，找出和 title 最相似的内容。比对的方法可以使用编辑距离或最长公共子串。
    - 如果未找到 h 节点，则只能使用 title 节点。
    - 网站 SEO 效果比较好，通常会添加一些 meta 标签，如 url、title、keywords、category 等信息，这些信息也可以成为一些参考依据
    - <meta property="og:title" content="故宫，你低调点！故宫：不，实力已不允许我继续低调">
    - 这里我们可以看到这个 meta 节点指定了 property 为 og:title，内容 content 就是标题内容

- 正文
    - 正文内容一般会被包含在 body 节点的 p 节点中，而且 p 节点一般不会独立存在，一般都会存在于 div 等节点内。
    - 正文内容对应的 p 节点也不一定全都是正文内容，可能掺杂其他的噪声，如网站的版权信息、发布人、文末广告等，这部分属于噪声。
    - 正文内容对应的 p 节点中会夹杂一些 style、script 等节点，并非正文内容。
    - 正文内容对应的 p 节点内可能包含 code、span 等节点，这些大部分属于正文中的特殊样式字符，多数情况下也需要归类到正文中。
    
    - 正文文本提取依据指标
        - 文本密度: 其实就类似单位节点所包含的文字个数
            - 基本上等同于单位标签内所包含的文字个数，但这里额外考虑了超链接的情况。
            - 因为一般来说，正文中所带的超链接是比较少的，而对于一些侧边栏、底栏一些区域，
            - 带有超链接的比率是非常高的，文本密度就会低下来，因此就容易排除了。
        - 符号密度: 文字数量和符号数量的比值
            - 正文中一般都带有标点符号，而网页链接、广告信息由于文字比较少，
            - 通常是不包含标点符号的，所以我们可以通过符号密度来排除一些内容。
    
    - 视觉识别：
        - 结合视觉来对正文进行识别。一般来说，正文所占的版面是最大的，所以我们可以通过计算节点所占区域的大小来排除一些干扰，
        - 比如如果我们查找到两块内容都疑似正文区域，而这两块区域的网页面积却一个很大，一个很小，那么面积大的是正文内容的可能性会更高。

- 发布时间
    - 一些正规的网站同样会把时间信息放到 meta 节点内，如上述例子中就多了这样的一个 meta 节点，
    - 内容如下：<meta name="og:time " content="2019-02-20 02:26:00">
    - 这里我们可以看到这个 meta 节点指定了 property 为 og:time，这是一种常见写法，
    - 其内容正好就是时间的信息，通过这部分信息我们也能进行时间的提取。
    
    - 提取依据：
        - 根据 meta 节点的信息进行提取。
        - 根据一些正则表达式来提取。发布」、「发表于」等关键字。
        - 根据节点和正文的距离来筛选更优节点。侧栏或底栏部分包含了时间的情况。

- 作者
    - 标准的网站会把 author 信息也加到 meta 节点里面，所以我们可以根据这个信息来提取
    - 固定的写法来匹配了，如一些关键字“作者”“编辑”“撰稿”，等等关键字。另外我们还可以根据一些常用的姓氏来进行一些优化和提取
    
    - 提取标准有：
        - 根据 meta 节点的信息进行提取。
        - 根据一些固定的关键词写法，用正则表达式来提取。
        - 根据一些常用的姓氏来对提取结果进行筛选。
        - 对和时间节点之间的距离进行计算，同样也可以成为筛选的依据


# 6 智能化解析代码实现
- 目标网址链接为：http://news.ifeng.com/c/7kQcQG2peWU，
- 本节我们主要实现的提取字段为标题、时间、正文内容

- 第一步：
    - 目标网页是一个静态网页，源码中可以看到页面的所有内容
    - 查看源码，复制下来之后我们把源代码保存成一个 html 文件，名字叫作 sample.html
    - 将 html 里面的字符转化成 lxml 里面的 HtmlElement 对象
```python
from lxml.html import HtmlElement, fromstring

html = open('sample.html', encoding='utf-8').read()
element = fromstring(html=html)
```
- element 对象其实就是整个网页对应的 HtmlElement 对象，其根节点就是 html，
- 下面我们会用到它来进行页面解析，从这个 HtmlElement 对象里面提取出我们想要的时间、标题、正文内容。